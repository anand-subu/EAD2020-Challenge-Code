{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import segmentation_models as sm\n",
    "import natsort\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import configparser\n",
    "from libtiff import TIFF\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "if os.environ[\"SM_FRAMEWORK\"] == \"tf.keras\":\n",
    "    from tensorflow.keras.utils import Sequence\n",
    "else:\n",
    "    from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted partially from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "\n",
    "class MultiLabelGenerator(Sequence):\n",
    "\n",
    "    \"\"\"MultiLabelGenerator for semantic segmentation architectures\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_ids,\n",
    "        image_path,\n",
    "        mask_path,\n",
    "        batch_size,\n",
    "        dim,\n",
    "        n_channels,\n",
    "        n_classes,\n",
    "        augment_flag,\n",
    "        tiff_flag,\n",
    "        to_fit=True,\n",
    "        shuffle=True,\n",
    "    ):\n",
    "\n",
    "        \"\"\"Initialization\n",
    "        :param file_ids: list of file names - for this dataset, the mapping between image to corresponding label file is based on common filename but different extension\n",
    "        :param image_path: path to images location\n",
    "        :param mask_path: path to masks location\n",
    "        :param to_fit: True to return X and y, False to return X only\n",
    "        :param batch_size: batch size at each iteration\n",
    "        :param dim: tuple indicating image dimension\n",
    "        :param n_channels: number of image channels\n",
    "        :param n_classes: number of output masks\n",
    "        :param augment_flag: boolean flag to indicate if augmentation should be enabled\n",
    "        :param shuffle: True to shuffle label indexes after every epoch\n",
    "        :param tiff_flag: Flag to indicate if labels should be parsed as TIFF files. Else it is assumed that they are in .npy format\n",
    "        \"\"\"\n",
    "\n",
    "        self.file_ids = file_ids\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.to_fit = to_fit\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.tiff_flag = tiff_flag\n",
    "        self.augment_flag = augment_flag\n",
    "        if augment_flag:\n",
    "            self.augmentor_dict = {\n",
    "                \"1\": iaa.OneOf([iaa.Fliplr(1)]),\n",
    "                \"2\": iaa.OneOf([iaa.Affine(scale={\"x\": (0.6, 1.2)}, order=[0])]),\n",
    "                \"3\": iaa.OneOf([iaa.Affine(rotate=(-20, 20), order=[0])]),\n",
    "                \"4\": iaa.OneOf([iaa.PerspectiveTransform(scale=(0.01, 0.2))]),\n",
    "                \"5\": iaa.OneOf([iaa.CropAndPad(percent=(-0.30, 0.30))]),\n",
    "                \"6\": iaa.OneOf([iaa.ElasticTransformation(alpha=(0.5, 2), sigma=0.25)]),\n",
    "                \"7\": iaa.OneOf(\n",
    "                    [\n",
    "                        iaa.AdditiveGaussianNoise(\n",
    "                            loc=0, scale=(0.0, 0.05 * 255), per_channel=0.5\n",
    "                        )\n",
    "                    ]\n",
    "                ),\n",
    "                \"8\": iaa.OneOf([iaa.AddToHueAndSaturation((-10, 10))]),\n",
    "                \"9\": iaa.OneOf([iaa.GaussianBlur((0, 1.0))]),\n",
    "                \"10\": iaa.OneOf([iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5))]),\n",
    "                \"11\": iaa.OneOf([iaa.LinearContrast((0.5, 1.0), per_channel=0.5)]),\n",
    "            }\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "\n",
    "        return int(np.floor(len(self.file_ids) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        file_ids_batch = [self.file_ids[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self._generate_X(file_ids_batch)\n",
    "\n",
    "        if self.to_fit:\n",
    "            y = self._generate_y(file_ids_batch)\n",
    "            if self.augment_flag:\n",
    "                X, y = self.augment_data(X, y)\n",
    "            return X, y\n",
    "\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def augment_data(self, X, y):\n",
    "        \"\"\"Augments a batch of data by randomly chosing one\n",
    "        of the augmentors defined in augment_dict.Returns\n",
    "        the transformed images and segmentation maps\"\"\"\n",
    "\n",
    "        random_choice = random.randint(1, len(self.augmentor_dict))\n",
    "        X_aug, y_aug = self.augmentor_dict[str(random_choice)](\n",
    "            images=X, segmentation_maps=y\n",
    "        )\n",
    "\n",
    "        return X_aug, y_aug\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "\n",
    "        self.indexes = np.arange(len(self.file_ids))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _generate_X(self, batch_file_ids):\n",
    "\n",
    "        \"\"\"Generates data containing batch_size images\n",
    "        :param list_IDs_temp: list of label ids to load\n",
    "        :return: batch of images\n",
    "        \"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels), dtype=np.uint8)\n",
    "\n",
    "        # Generate data\n",
    "        for i, file_id_name in enumerate(batch_file_ids):\n",
    "            # Store sample\n",
    "            X[i,] = self._load_image(os.path.join(self.image_path, file_id_name + \".jpg\"))\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _generate_y(self, batch_file_ids):\n",
    "\n",
    "        \"\"\"Generates data containing batch_size masks\n",
    "        :param list_IDs_temp: list of label ids to load\n",
    "        :return: batch if masks\n",
    "        \"\"\"\n",
    "        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=np.int8)\n",
    "\n",
    "        # Generate data\n",
    "        if self.tiff_flag:\n",
    "            for i, file_id_name in enumerate(batch_file_ids):\n",
    "                # Store sample\n",
    "                y[i,] = self._load_tif(os.path.join(self.mask_path, file_id_name + \".tif\"))\n",
    "\n",
    "            return y\n",
    "        else:\n",
    "            for i, file_id_name in enumerate(batch_file_ids):\n",
    "                # Store sample\n",
    "                y[i,] = self._load_npy(os.path.join(self.mask_path, file_id_name + \".npy\"))\n",
    "\n",
    "            return y\n",
    "\n",
    "    def _load_image(self, image_path):\n",
    "\n",
    "        \"\"\"Loads image\n",
    "        :param image_path: path to image to load\n",
    "        :return: image\n",
    "        \"\"\"\n",
    "        if (self.n_channels == 1):\n",
    "            img = cv2.imread(image_path,cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        else:\n",
    "            img = cv2.imread(image_path)\n",
    "            \n",
    "        img = cv2.resize(img, self.dim)\n",
    "        return img\n",
    "\n",
    "    def _load_tif(self, mask_path):\n",
    "\n",
    "        \"\"\"Load TIF masks after applying\n",
    "        preprocessing to convert the masks\n",
    "        :param mask_path: path to mask to load\n",
    "        :return: mask image\"\"\"\n",
    "\n",
    "        mask_tif = TIFF.open(mask_path, mode=\"r\")\n",
    "        mask_annot = mask_tif.iter_images()\n",
    "        temp_list = []\n",
    "\n",
    "        for mask_images in mask_annot:\n",
    "\n",
    "            mask_images[mask_images <= 15] = 0  # just intended as a sanity check; practically the mask has either 0 or 255, but this range is set to handle any encoding issues between formats that may cause some stray pixels to take up values a little greater than 0\n",
    "            mask_images[mask_images > 15] = 1\n",
    "            temp_list.append(\n",
    "                cv2.resize(mask_images, self.dim, interpolation=cv2.INTER_NEAREST)\n",
    "            )\n",
    "\n",
    "        mask_image = cv2.merge(tuple(temp_list))\n",
    "\n",
    "        return mask_image\n",
    "\n",
    "    def _load_npy(self, mask_path_npy):\n",
    "\n",
    "        \"\"\"Load TIF masks after applying\n",
    "        preprocessing to convert the masks\n",
    "        :param mask_path: path to mask to load\n",
    "        :return: mask image\"\"\"\n",
    "\n",
    "        temp_list = []\n",
    "        mask = np.load(mask_path_npy)\n",
    "        for i in range(self.n_classes):\n",
    "            temp_list.append(\n",
    "                cv2.resize(mask[:, :, i], self.dim, interpolation=cv2.INTER_NEAREST)\n",
    "            )\n",
    "\n",
    "        mask_image = cv2.merge(tuple(temp_list))\n",
    "\n",
    "        return mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_file_names(image_dir, masks_dir):\n",
    "    \n",
    "    \"\"\"Generates file names present in image directory and corresponding mask directory\n",
    "    :param image_dir: Path to images\n",
    "    :param masks_dir: Path to masks\n",
    "    :return: tuple of image file paths and mask file paths present in respective directories\n",
    "    \"\"\"\n",
    "    \n",
    "    image_file_paths_train = []\n",
    "    mask_file_paths_train = []\n",
    "\n",
    "    train_files = natsort.natsorted(os.listdir(image_dir))\n",
    "    image_file_paths_train += [os.path.splitext(x)[0] for x in train_files]\n",
    "\n",
    "    mask_files = natsort.natsorted(os.listdir(masks_dir))\n",
    "\n",
    "    mask_file_paths_train += [os.path.splitext(x)[0] for x in mask_files]\n",
    "\n",
    "    return image_file_paths_train, mask_file_paths_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"segmentation_training.ini\")\n",
    "\n",
    "TRAIN_IMAGES_PATH = config[\"IMAGE_FOLDERS\"][\"train_images_path\"]\n",
    "TRAIN_MASKS_PATH = config[\"IMAGE_FOLDERS\"][\"train_masks_path\"]\n",
    "VAL_IMAGES_PATH = config[\"IMAGE_FOLDERS\"][\"val_images_path\"]\n",
    "VAL_MASKS_PATH = config[\"IMAGE_FOLDERS\"][\"val_masks_path\"]\n",
    "\n",
    "AUGMENT_FLAG = config[\"DATA_GENERATOR_PARAMETERS\"].getboolean(\"augment_flag\")\n",
    "TIFF_FLAG = config[\"DATA_GENERATOR_PARAMETERS\"].getboolean(\"tiff_flag\")\n",
    "IMAGE_DIMENSIONS = tuple(\n",
    "    map(\n",
    "        lambda x: int(x),\n",
    "        config[\"DATA_GENERATOR_PARAMETERS\"][\"image_dimensions\"].split(\",\"),\n",
    "    )\n",
    ")\n",
    "NUM_CHANNELS = int(config[\"DATA_GENERATOR_PARAMETERS\"][\"num_channels\"])\n",
    "NUM_CLASSES = int(config[\"DATA_GENERATOR_PARAMETERS\"][\"num_classes\"])\n",
    "BATCH_SIZE = int(config[\"DATA_GENERATOR_PARAMETERS\"][\"batch_size\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Unet_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
